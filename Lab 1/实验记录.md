## 实验

整个仓库包含以下文件，标注了一下实验对应的文件夹。

```bash
6.824
├── Makefile
└── src
    ├── go.mod
    ├── go.sum
    ├── kvraft      # lab 3
    ├── labgob
    ├── labrpc
    ├── main
    ├── models
    ├── mr          # lab 1
    ├── mrapps
    ├── porcupine
    ├── raft        # lab 2
    ├── shardctrler # lab 4a
    └── shardkv     # lab 4b
```

第一个实验是实现本地的 MapReduce，需要对 mr 文件夹下的三个文件补充内容：
- `src/mr/coordinator.go`：协调者，维护状态（全局共享）
- `src/mr/worker.go`：工作者，执行 map/reduce 任务
- `src/mr/rpc.go`：RPC 调用的请求和回复

测试程序将启动一个协调者和多个工作者。生成新的工作者时，它将通过 RPC 调用向协调者请求任务，然后执行接收到的任务，产生输出，最后报告结果。重复这些步骤直到完成整个 MapReduce 工作。

### 整体思路

可以看 2021-Lecture6 视频讲解，整体如下：

1. 由 worker 向 coordinator 请求任务，coordinator 不用维护 worker，因为宕机或超时都要重新分派任务；
2. worker 完成 Map 或 Reduce 任务后，都先将输出写入临时文件，然后再重命名；
3. 由 worker 执行 Reduce 任务中的排序工作，减轻 coordinator 负担；
4. worker 完成任务后，向 coordinator 报告完成的任务类型和编号；
5. coordinator 根据目前的任务状态，决定分派 Map、Reduce 还是 Done 任务，Done 表示整个 MapReduce 任务已经完成，worker 可以自行退出；
6. 只有 Map 任务全部完成后才能分派 Reduce 任务，因此当 Map 任务都在执行时，coordinator 不回复 worker 的请求；
7. 当 Reduce 任务都在执行时，coordinator 也不回复 worker 的请求；
8. 当所有 Reduce 任务完成后，coordinator 将全局状态 `isDone` 设置为真，表示整个 MapReduce 任务完成，周期调用的 `Done()` 函数会检测到该状态；
9. 此时若 worker 又向 coordinator 请求任务，则分派 Done 任务，这里不管 worker 是否正确退出。

关于条件变量 `sync.Cond` 的使用可以看 2020-Lecture5 视频，使用互斥锁初始化，在条件不满足时等待，完成相关动作后唤醒：
- 这里可以用 `defer`

```
mu.Lock()
// do something that might affect the condition
cond.Broadcast()
mu.Unlock()
```

### RPC

1. 任务类型

如前所述，加上 `Done` 一共有三种类型：

```go
type TaskType int

const (
	Map TaskType = iota
	Reduce
	Done
)
```

2. worker 向 coordinator 请求任务

由 coordinator 决定分派的任务，因此请求体为空：

```go
type GetTaskArgs struct{}
```

3. coordinator 向 worker 分派任务

一共有三种类型的任务，所有任务都有 `TaskType` 和 `TaskNum` 表示类型和任务编号
- Map：`MapFile` 表示读取的输入文件，`NReduceTasks` 表示 Reduce 任务的数量
  - 写入中间文件 `mr-mapTaskN-reduceTaskN`
- Reduce：`nMapTasks` 表示中间文件的数量（== Map 任务的数量 == 输入文件的数量）
  - 写入最终文件 `mr-out-reduceTaskN`

```go
type GetTaskReply struct {
	TaskType TaskType
	TaskNum int
	NReduceTasks int
	MapFile string
	NMapTasks int
}
```

4. worker 向 coordinator 报告任务完成

需要报告完成的任务类型和任务编号：

```go
type FinishedTaskArgs struct {
	TaskType TaskType
	TaskNum int
}
```

### worker

轮询请求任务，根据任务类型执行相应动作，最后报告完成。

```go
func Worker(mapf func(string, string) []KeyValue,
	reducef func(string, []string) string) {

	for {
		args := GetTaskArgs{}
		reply := GetTaskReply{}
		call("Coordinator.HandleGetTask", &args, &reply)

		switch reply.TaskType {
		case Map:
			performMap(reply.MapFile, reply.TaskNum, reply.NReduceTasks, mapf)
		case Reduce:
			performReduce(reply.TaskNum, reply.NMapTasks, reducef)
		case Done:
			os.Exit(0)
		default:
			log.Fatal("Bad finished task? %s", reply.TaskType)
		}

		finargs := FinishedTaskArgs{
			TaskType: reply.TaskType,
			TaskNum:  reply.TaskNum,
		}
		finreply := FinishedTaskReply{}
		call("Coordinator.HandleFinishedTask", &finargs, &finreply)
	}
}
```

定义工具函数，用于读取中间文件，以及将临时文件重命名为中间文件或最终文件。

```go
func finalizeReduceFile(tmpFile string, taskN int) {
	finalFile := fmt.Sprintf("mr-out-%d", taskN)
	os.Rename(tmpFile, finalFile)
}

func getIntermediateFile(mapTaskN int, reduceTaskN int) string {
	return fmt.Sprintf("mr-%d-%d", mapTaskN, reduceTaskN)
}

func finalizeIntermediateFile(tmpFile string, mapTaskN int, reduceTaskN int) {
	finalFile := getIntermediateFile(mapTaskN, reduceTaskN)
	os.Rename(tmpFile, finalFile)
}
```

执行 Map 任务：读取文件，调用 `mapf`，写入临时文件，重命名为中间文件。

```go
func performMap(filename string, taskNum int, nReduceTasks int, mapf func(string, string) []KeyValue) {
	file, err := os.Open(filename)
	if err != nil {
		log.Fatalf("cannot open %v", filename)
	}
	content, err := ioutil.ReadAll(file)
	if err != nil {
		log.Fatalf("cannot read %v", filename)
	}
	file.Close()

	kva := mapf(filename, string(content))
	tmpFiles := []*os.File{}
	tmpFilenames := []string{}
	encoders := []*json.Encoder{}
	for r := 0; r < nReduceTasks; r++ {
		tmpFile, err := ioutil.TempFile("", "")
		if err != nil {
			log.Fatalf("cannot open tmpfile")
		}
		tmpFiles = append(tmpFiles, tmpFile)
		tmpFilename := tmpFile.Name()
		tmpFilenames = append(tmpFilenames, tmpFilename)
		enc := json.NewEncoder(tmpFile)
		encoders = append(encoders, enc)
	}

	for _, kv := range kva {
		r := ihash(kv.Key) % nReduceTasks
		encoders[r].Encode(&kv)
	}
	for _, f := range tmpFiles {
		f.Close()
	}
	for r := 0; r < nReduceTasks; r++ {
		finalizeIntermediateFile(tmpFilenames[r], taskNum, r)
	}
}
```

定义工具函数，用于排序键值对。

```go
type ByKey []KeyValue

func (a ByKey) Len() int           { return len(a) }
func (a ByKey) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }
func (a ByKey) Less(i, j int) bool { return a[i].Key < a[j].Key }
```

执行 Reduce 任务：根据任务编号读取中间文件，按键排序，对键对应的所有数据调用 `reducef`，写入临时文件，重命名为最终文件。

```go
func performReduce(taskNum int, nMapTasks int, reducef func(string, []string) string) {
	kva := []KeyValue{}
	for m := 0; m < nMapTasks; m++ {
		iFilename := getIntermediateFile(m, taskNum)
		file, err := os.Open(iFilename)
		if err != nil {
			log.Fatalf("cannot open %v", iFilename)
		}
		dec := json.NewDecoder(file)
		for {
			var kv KeyValue
			if err := dec.Decode(&kv); err != nil {
				break
			}
			kva = append(kva, kv)
		}
		file.Close()
	}

	sort.Sort(ByKey(kva))

	tmpFile, err := ioutil.TempFile("", "")
	if err != nil {
		log.Fatalf("cannot open tmpfile")
	}
	tmpFilename := tmpFile.Name()

	key_begin := 0
	for key_begin < len(kva) {
		key_end := key_begin + 1
		for key_end < len(kva) && kva[key_end].Key == kva[key_begin].Key {
			key_end++
		}
		values := []string{}
		for k := key_begin; k < key_end; k++ {
			values = append(values, kva[k].Value)
		}
		output := reducef(kva[key_begin].Key, values)

		fmt.Fprintf(tmpFile, "%v %v\n", kva[key_begin].Key, output)

		key_begin = key_end
	}

	finalizeReduceFile(tmpFilename, taskNum)
}
```

### coordinator

维护整个 MapReduce 任务状态，并发处理 worker 请求时需要保护共享状态，因此使用条件变量；记录 Map 和 Reduce 任务的分派和完成情况（就不用维护 worker 了）；最后用一个变量表示整个 MapReduce 任务是否完成。

```go
type Coordinator struct {
	mu   sync.Mutex
	cond *sync.Cond

	mapFiles     []string
	nMapTasks    int
	nReduceTasks int

	mapTasksFinished    []bool
	mapTasksIssued      []time.Time
	reduceTasksFinished []bool
	reduceTasksIssued   []time.Time

	isDone bool
}
```

处理 worker 请求任务，有三种任务可以分派：
- Map：未分派或超时，分派任务并记录分派时间；已分派完毕，等待 Map 任务完成
- Reduce：未分派或超时，分派任务并记录分派时间；已分派完毕，等待 Reduce 任务完成
- Done：所有任务都完成

```go
func (c *Coordinator) HandleGetTask(args *GetTaskArgs, reply *GetTaskReply) error {
	c.mu.Lock()
	defer c.mu.Unlock()

	reply.NReduceTasks = c.nReduceTasks
	reply.NMapTasks = c.nMapTasks

	for {
		mapDone := true
		for m, done := range c.mapTasksFinished {
			if !done {
				if c.mapTasksIssued[m].IsZero() ||
					time.Since(c.mapTasksIssued[m]).Seconds() > 10 {
					reply.TaskType = Map
					reply.TaskNum = m
					reply.MapFile = c.mapFiles[m]
					c.mapTasksIssued[m] = time.Now()
					return nil
				} else {
					mapDone = false
				}
			}
		}

		if !mapDone {
			c.cond.Wait()
		} else {
			break
		}
	}

	for {
		reduceDone := true
		for r, done := range c.reduceTasksFinished {
			if !done {
				if c.reduceTasksIssued[r].IsZero() ||
					time.Since(c.reduceTasksIssued[r]).Seconds() > 10 {
					reply.TaskType = Reduce
					reply.TaskNum = r
					c.reduceTasksIssued[r] = time.Now()
					return nil
				} else {
					reduceDone = false
				}
			}
		}

		if !reduceDone {
			c.cond.Wait()
		} else {
			break
		}
	}

	reply.TaskType = Done
	c.isDone = true

	return nil
}
```

处理 worker 报告任务完成，记录 Map/Reduce 完成状态，最后唤醒等待的线程（即没有任务分派处于等待的线程）。

```go
func (c *Coordinator) HandleFinishedTask(args *FinishedTaskArgs, reply *FinishedTaskReply) error {
	c.mu.Lock()
	defer c.mu.Unlock()

	switch args.TaskType {
	case Map:
		c.mapTasksFinished[args.TaskNum] = true
	case Reduce:
		c.reduceTasksFinished[args.TaskNum] = true
	default:
		log.Fatal("Bad finished task? %s", args.TaskType)
	}

	c.cond.Broadcast()

	return nil
}
```

MapReduce 任务完成，coordinator 退出。

```go
func (c *Coordinator) Done() bool {
	c.mu.Lock()
	defer c.mu.Unlock()
	return c.isDone
}
```

创建 coordinator 时的一些初始化操作。

```go
func MakeCoordinator(files []string, nReduce int) *Coordinator {
	c := Coordinator{}

	c.mu = sync.Mutex{}
	c.cond = sync.NewCond(&c.mu)
	c.mapFiles = files
	c.nMapTasks = len(files)
	c.mapTasksFinished = make([]bool, len(files))
	c.mapTasksIssued = make([]time.Time, len(files))

	c.nReduceTasks = nReduce
	c.reduceTasksFinished = make([]bool, nReduce)
	c.reduceTasksIssued = make([]time.Time, nReduce)

	go func() {
		for {
			c.mu.Lock()
			c.cond.Broadcast()
			c.mu.Unlock()
			time.Sleep(time.Second)
		}
	}()

	c.server()
	return &c
}
```


## 测试

仓库下载到 Windows 再拷贝到 Linux 系统会有格式问题，bash 脚本跑不了可以试试替换：

```bash
sed -i 's/\r$//' filename
```

执行测试脚本，验证实现是否通过：

```bash
cd ~/6.824/src/main
bash test-mr.sh
```

RPC 警告可以忽略，例如：

```bash
2021/11/23 13:09:09 rpc.Register: method "Done" has 1 input parameters; needs exactly three
```

通过所有测试，如下：

```bash
jck@ubuntu:~/6.824/src/main$ bash test-mr.sh
# *** Starting wc test.
# 2021/11/23 14:14:45 rpc.Register: method "Done" has 1 input parameters; needs exactly three
# --- wc test: PASS
# *** Starting indexer test.
# 2021/11/23 14:14:56 rpc.Register: method "Done" has 1 input parameters; needs exactly three
# --- indexer test: PASS
# *** Starting map parallelism test.
# 2021/11/23 14:15:00 rpc.Register: method "Done" has 1 input parameters; needs exactly three
# --- map parallelism test: PASS
# *** Starting reduce parallelism test.
# 2021/11/23 14:15:07 rpc.Register: method "Done" has 1 input parameters; needs exactly three
# --- reduce parallelism test: PASS
# *** Starting job count test.
# 2021/11/23 14:15:15 rpc.Register: method "Done" has 1 input parameters; needs exactly three
# test-mr.sh: line 171: obcount.so: command not found
# --- job count test: PASS
# *** Starting early exit test.
# 2021/11/23 14:15:31 rpc.Register: method "Done" has 1 input parameters; needs exactly three
# --- early exit test: PASS
# *** Starting crash test.
# 2021/11/23 14:15:37 rpc.Register: method "Done" has 1 input parameters; needs exactly three
# --- crash test: PASS
# *** PASSED ALL TESTS
```
